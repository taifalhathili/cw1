{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\c2034122\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\c2034122\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\c2034122\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Library for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# os library is used here for file path locatain\n",
    "import os\n",
    "\n",
    "# numpy is used for numerical operation\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this piece of code, we extract the data from text file and put it in columns\n",
    "\n",
    "# \"bbc\" is the folder of the dataset\n",
    "directory = 'bbc'\n",
    "\n",
    "# we created a dataframe with two columns \"news\" that is text related to business, tech etc and a category for text\n",
    "data_frame = pd.DataFrame(columns=['news', 'category'])\n",
    "\n",
    "id_count = 0\n",
    "\n",
    "# In the below code the for loop will go through the text files and get the text from each file and put it in dataframe column.\n",
    "# the folders name is tech, business etc. and it is pushed to \"news\" columns\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if not file.startswith(\"READ\"):\n",
    "            category = subdir.replace('bbc\\\\','')\n",
    "            \n",
    "            with open(os.path.join(subdir, file)) as f:\n",
    "                data = \" \".join(line.rstrip() for line in f)\n",
    "                data_frame = data_frame.append(pd.DataFrame([[data, category]], columns=['news', 'category']), ignore_index = True)\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_frame.to_csv('Prepared_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only to upload csv file to colab\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('Prepared_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate Category names with numerical index and save it in new column category_id\n",
    "data_frame['category_id'] = data_frame['category'].factorize()[0]\n",
    "\n",
    "# map the categories_name to number\n",
    "category_id_df = data_frame[['category', 'category_id']].drop_duplicates().sort_values('category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 news  category_id\n",
       "ID                                                                \n",
       "0   Ad sales boost Time Warner profit  Quarterly p...            0\n",
       "1   Dollar gains on Greenspan speech  The dollar h...            0\n",
       "2   Yukos unit buyer faces loan claim  The owners ...            0\n",
       "3   High fuel prices hit BA's profits  British Air...            0\n",
       "4   Pernod takeover talk lifts Domecq  Shares in U...            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ",  insert ID column\n",
    "data_frame['ID'] = range(0, len(data_frame))\n",
    "\n",
    "# set ID as an index\n",
    "data_frame = data_frame.set_index('ID')\n",
    "\n",
    "# Dropping the category column. here we can also use the drop function\n",
    "data_frame = data_frame[['news', 'category_id']]\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataframe for machine learning model\n",
    "from sklearn.utils import shuffle\n",
    "data_frame = shuffle(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Guantanamo pair's passport ban  The government...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Brussels raps mobile call charges  The Europea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>US economy still growing says Fed  Most areas ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>TV debate urged for party chiefs  Broadcasters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>New 'yob' targets to be unveiled  Fifty new ar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   news  category_id\n",
       "ID                                                                  \n",
       "960   Guantanamo pair's passport ban  The government...            2\n",
       "112   Brussels raps mobile call charges  The Europea...            0\n",
       "462   US economy still growing says Fed  Most areas ...            0\n",
       "1243  TV debate urged for party chiefs  Broadcasters...            2\n",
       "987   New 'yob' targets to be unveiled  Fifty new ar...            2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will remove the garbage data that will not be helpful to our model\n",
    "def data_preprocessing(news):\n",
    "    # Replace new line with null if any exist also remove the carriage return\n",
    "    news = news.lower().replace('\\n', ' ').replace('\\r', '').strip()\n",
    "    # to remove multiple spaces we will be using a regex expression. it will replace\n",
    "    # multiple spaces with single space\n",
    "    news = re.sub(' +', ' ', news)\n",
    "    # to get alphabets\n",
    "    news = re.sub(r'[^\\w\\s]', '', news)\n",
    "    \n",
    "    # we will be removing stopwords like and, or etc.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # list of words include in news article\n",
    "    word_tokens = word_tokenize(news)\n",
    "    # this will remove all unnecessary words specified in nltk stopwords file\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    news = ' '.join(filtered_sentence)\n",
    "    return news\n",
    "\n",
    "data_frame['news'] = data_frame['news'].apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)\n",
    "\n",
    "data_frame['news_noun_adj'] = data_frame.news.apply(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['news'] = data_frame['news'] + data_frame['news_noun_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate word from a string.\n",
    "data_frame['news'] = data_frame.news.str.split().apply(lambda x: OrderedDict.fromkeys(x).keys()).str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for category and their ID.\n",
    "# we need it later\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'category']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(data_frame.news).toarray() \n",
    "\n",
    "labels = data_frame.category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 11719)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>category_id</th>\n",
       "      <th>news_noun_adj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>guantanamo pairs passport ban government writt...</td>\n",
       "      <td>2</td>\n",
       "      <td>guantanamo pairs passport ban government briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>brussels raps mobile call charges european com...</td>\n",
       "      <td>0</td>\n",
       "      <td>brussels call charges european commission mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>us economy still growing says fed areas saw co...</td>\n",
       "      <td>0</td>\n",
       "      <td>economy areas economy continue early january f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>tv debate urged party chiefs broadcasters fix ...</td>\n",
       "      <td>2</td>\n",
       "      <td>tv debate party chiefs broadcasters date preel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>new yob targets unveiled fifty areas getting s...</td>\n",
       "      <td>2</td>\n",
       "      <td>new yob targets fifty new areas special help a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   news  category_id  \\\n",
       "ID                                                                     \n",
       "960   guantanamo pairs passport ban government writt...            2   \n",
       "112   brussels raps mobile call charges european com...            0   \n",
       "462   us economy still growing says fed areas saw co...            0   \n",
       "1243  tv debate urged party chiefs broadcasters fix ...            2   \n",
       "987   new yob targets unveiled fifty areas getting s...            2   \n",
       "\n",
       "                                          news_noun_adj  \n",
       "ID                                                       \n",
       "960   guantanamo pairs passport ban government briti...  \n",
       "112   brussels call charges european commission mobi...  \n",
       "462   economy areas economy continue early january f...  \n",
       "1243  tv debate party chiefs broadcasters date preel...  \n",
       "987   new yob targets fifty new areas special help a...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'business':\n",
      "  . unigrams: economic, prices, investors, stock, economy, analysts, oil, bank, growth, shares\n",
      "  . bigrams: analysts said, stock exchange, securities exchange, exchange commission, told reuters, economic growth, news agency, chief executive, oil prices, stock market\n",
      "'entertainment':\n",
      "  . unigrams: stars, starring, album, award, comedy, awards, actress, singer, actor, film\n",
      "  . bigrams: golden globe, leonardo dicaprio, film festival, named best, imelda staunton, vera drake, dollar baby, million dollar, box office, los angeles\n",
      "'politics':\n",
      "  . unigrams: leader, tony, liberal, secretary, party, blair, tories, tory, election, labour\n",
      "  . bigrams: tory leader, radio 4s, liberal democrat, leader michael, lib dems, prime minister, liberal democrats, michael howard, general election, tony blair\n",
      "'sport':\n",
      "  . unigrams: rugby, victory, champion, win, game, season, injury, match, cup, coach\n",
      "  . bigrams: coach andy, sir alex, manchester united, rbs nations, australian open, world cup, world number, champions league, bbc sport, grand slam\n",
      "'tech':\n",
      "  . unigrams: devices, microsoft, web, pc, online, digital, computer, software, technology, users\n",
      "  . bigrams: playstation portable, hugely popular, media player, open source, sony psp, hard drive, mobile phones, bbc news, consumer electronics, news website\n"
     ]
    }
   ],
   "source": [
    "# Importing chi-square for feature selection\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# number of words in a perticular set\n",
    "Num_of_words = 10\n",
    "\n",
    "# Find correlation between words and categories\n",
    "for Category, category_id in sorted(category_to_id.items()):\n",
    "    # apply chi-square to all features in categories.\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    \n",
    "    # list of top unigrams with chi-square.\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    \n",
    "    # list of top bigrams with chi-square.\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    \n",
    "    # display the category\n",
    "    print(\"'{}':\".format(Category))\n",
    "    \n",
    "    # display top 10 unigrams\n",
    "    print(\"  . unigrams: {}\".format(', '.join(unigrams[-Num_of_words:])))\n",
    "    \n",
    "    # display top 10 bigrams\n",
    "    print(\"  . bigrams: {}\".format(', '.join(bigrams[-Num_of_words:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we are using Decision tree classifier\n",
    "model_dec_tree = DecisionTreeClassifier(random_state=1)\n",
    "model_log_reg = LogisticRegression(random_state=1)\n",
    "model_naive = GaussianNB()\n",
    "model_svc = SVC(random_state=1)\n",
    "\n",
    "#Split Data \n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, data_frame.index, test_size=0.20, random_state=2)\n",
    "\n",
    "#Train model\n",
    "model_dec_tree.fit(X_train, y_train)\n",
    "model_log_reg.fit(X_train, y_train)\n",
    "model_naive.fit(X_train, y_train)\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred_dec_tree = model_dec_tree.predict(X_test)\n",
    "y_pred_log_reg = model_log_reg.predict(X_test)\n",
    "y_pred_naive = model_naive.predict(X_test)\n",
    "y_pred_svc = model_svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision tree:  0.8134831460674158\n",
      "Accuracy of Logistic regression:  0.9752808988764045\n",
      "Accuracy of Naive bayes:  0.952808988764045\n",
      "Accuracy of SVC:  0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy of Decision tree: \", accuracy_score(y_test, y_pred_dec_tree))\n",
    "print(\"Accuracy of Logistic regression: \", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy of Naive bayes: \", accuracy_score(y_test, y_pred_naive))\n",
    "print(\"Accuracy of SVC: \", accuracy_score(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76        97\n",
      "           1       0.84      0.69      0.75        83\n",
      "           2       0.85      0.82      0.83        89\n",
      "           3       0.92      0.87      0.89       105\n",
      "           4       0.78      0.85      0.81        71\n",
      "\n",
      "    accuracy                           0.81       445\n",
      "   macro avg       0.82      0.81      0.81       445\n",
      "weighted avg       0.82      0.81      0.81       445\n",
      "\n",
      "Classification report for Logistic regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        97\n",
      "           1       0.99      0.96      0.98        83\n",
      "           2       0.99      0.97      0.98        89\n",
      "           3       0.99      0.99      0.99       105\n",
      "           4       0.99      0.96      0.97        71\n",
      "\n",
      "    accuracy                           0.98       445\n",
      "   macro avg       0.98      0.97      0.97       445\n",
      "weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "Classification report for Naive bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        97\n",
      "           1       0.99      0.87      0.92        83\n",
      "           2       0.94      0.99      0.96        89\n",
      "           3       1.00      0.99      1.00       105\n",
      "           4       0.85      0.99      0.92        71\n",
      "\n",
      "    accuracy                           0.95       445\n",
      "   macro avg       0.95      0.95      0.95       445\n",
      "weighted avg       0.96      0.95      0.95       445\n",
      "\n",
      "Classification report for SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        97\n",
      "           1       0.99      0.96      0.98        83\n",
      "           2       0.98      0.97      0.97        89\n",
      "           3       0.99      0.99      0.99       105\n",
      "           4       0.99      0.96      0.97        71\n",
      "\n",
      "    accuracy                           0.97       445\n",
      "   macro avg       0.97      0.97      0.97       445\n",
      "weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for Decision Tree')\n",
    "print(classification_report(y_test, y_pred_dec_tree))\n",
    "print('Classification report for Logistic regression')\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print('Classification report for Naive bayes')\n",
    "print(classification_report(y_test, y_pred_naive))\n",
    "print('Classification report for SVC')\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input news:saudi arabia is rich country\n",
      "Decision tree Predicted as:  business\n"
     ]
    }
   ],
   "source": [
    "# Decision tree: testing the model on user input data\n",
    "text_features = tfidf.transform([input('Input news:')])\n",
    "prediction = model_dec_tree.predict(text_features)\n",
    "\n",
    "print(\"Decision tree Predicted as: \", id_to_category[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input news:manchester city win the champion\n",
      "Logistic regression Predicted as:  sport\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression: testing the model on user input data\n",
    "text_features = tfidf.transform([input('Input news:')])\n",
    "prediction = model_log_reg.predict(text_features)\n",
    "\n",
    "print(\"Logistic regression Predicted as: \", id_to_category[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
